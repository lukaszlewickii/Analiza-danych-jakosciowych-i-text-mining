{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macierz wystąpień"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tekst = [\"@ayyytylerb that is so true drink lots of coffee\",\n",
    "\"RT @bryzy_brib: Senior March tmw morning at 7:25 A.M. in the SENIOR lot. Get up early, make yo coffee/breakfast, cus this will only happen ?\",\n",
    "\"If you believe in #gunsense tomorrow would be a very good day to have your coffee any place BUT @Starbucks Guns+Coffee=#nosense @MomsDemand\",\n",
    "\"My cute coffee mug. http://t.co/2udvMU6XIG\",\n",
    "\"RT @slaredo21: I wish we had Starbucks here... Cause coffee dates in the morning sound perff!\",\n",
    "\"Does anyone ever get a cup of coffee before a cocktail??\",\n",
    "\"I like my coffee like I like my women...black, bitter, and preferably fair trade. I love #Archer\",\n",
    "\"@dreamwwediva ya didn't have coffee did ya?\",\n",
    "\"RT @iDougherty42: I just want\\r\\n some coffee.\",\n",
    "\"RT @Dorkv76: I can't care before coffee.\",\n",
    "\"No lie I wouldn't mind coming home smelling like coffee\",\n",
    "\"RT @JonasWorldFeed: Play Ping Pong with Joe. Take a tour of the stage with Nick. Have coffee with Kevin. Charity auction: https://t.co/VTkK?\",\n",
    "\"Have I ever told any of you that Tate Donovan bought my stepmom coffee?\",\n",
    "\"RT @JonasWorldFeed: Play Ping Pong with Joe. Take a tour of the stage with Nick. Have coffee with Kevin. Charity auction: https://t.co/VTkK?\",\n",
    "\"@HeatherWhaley I was about 2 joke it takes 2 hands to hold hot coffee...then I read headline! #Don'tDrinkNShoot\",\n",
    "\"RT @MoveTheSticks: Charlie Whitehurst looks like he should be working \\nat a coffee shop in Portland or hosting a renovation show on HGTV.\",\n",
    "\"Coffee always makes everything better.\",\n",
    "\"RT @AdelaideReview: Food For Thought: @Annabelleats shares a delicious Venison and Porcini Mushroom Pie Recipe. http://t.co/N8O7vqFKWN http?\",\n",
    "\"RT @LittleMelss: lmfao!!!@bryanlaca: nahhh Melanie u is fa sho like an ummm a Coffee table ;) ) yeeeee lmaoo\",\n",
    "\"I wonder if Christian Colon will get a cup of coffee once the rosters\\r expand to 40 man in September. Really nothing to lose by doing so.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "stopwords = [\"a\", \"able\", \"about\", \"across\", \"after\", \"all\", \"almost\", \"also\", \"am\", \"among\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"but\", \"by\", \"can\", \"cannot\", \"could\", \"dear\", \"did\", \"do\", \"does\", \"either\", \"else\", \"ever\", \"every\", \"for\", \"from\", \"get\", \"got\", \"had\", \"has\", \"have\", \"he\", \"her\", \"hers\", \"him\", \"his\", \"how\", \"however\", \"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"just\", \"least\", \"let\", \"like\", \"likely\", \"may\", \"me\", \"might\", \"most\", \"must\", \"my\", \"neither\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"often\", \"on\", \"only\", \"or\", \"other\", \"our\", \"own\", \"rather\", \"said\", \"say\", \"says\", \"she\", \"should\", \"since\", \"so\", \"some\", \"than\", \"that\", \"the\", \"their\", \"them\", \"then\", \"there\", \"these\", \"they\", \"this\", \"tis\", \"to\", \"too\", \"twas\", \"us\", \"wants\", \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"would\", \"yet\", \"you\", \"your\"]\n",
    "\n",
    "def czysc_tekst(tekst):\n",
    "    \n",
    "    temp = re.sub(\"\\s{2,}\", \" \", tekst)\n",
    "    temp = re.sub(\"(\\r\\n|\\r|\\n)\", \" \", temp) \n",
    "    temp = temp.lower() \n",
    "    temp = re.sub(\"rt\", \"\", temp) \n",
    "    temp = re.sub(\"&amp\", \"\", temp) \n",
    "    temp = re.sub(\"#[a-z,A-Z]*\", \"\", temp)\n",
    "    temp = re.sub(\"@\\w+\", \"\", temp) \n",
    "    temp = re.sub(\"(f|ht)(tp)([^ ]*)\", \"\", temp) \n",
    "    temp = re.sub(\"http(s?)([^ ]*)\", \"\", temp)\n",
    "    temp = re.sub(\"[!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~]\", \"\", temp) \n",
    "    temp = re.sub(\"\\d\", \"\", temp) \n",
    "    temp = re.sub(\"\\s{2,}\", \" \", temp) \n",
    "    temp = temp.strip()\n",
    "    return temp\n",
    "\n",
    "# Czyszczenie i normalizacja\n",
    "czysty = [czysc_tekst(el) for el in tekst]\n",
    "\n",
    "# Wyodrębnianie tokenów\n",
    "tokeny = [re.split(\"\\s\", el) for el in czysty]\n",
    "\n",
    "# usunięcie stopwords\n",
    "termy = [[t for t in el if t not in stopwords] for el in tokeny]\n",
    "\n",
    "# Wyodrębnianie rdzeni\n",
    "termy_stem = [[stemmer.stem(t) for t in el] for el in termy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termy_all = [term for el in termy_stem for term in el]\n",
    "unikaty = list(set(termy_all))\n",
    "\n",
    "print(f'Wszystkich termów jest {len(termy_all)} ale unikatowych jest {len(unikaty)}')\n",
    "print(unikaty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macierz dokument-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tworz_dtm(termy_stem, unikaty):    \n",
    "\n",
    "    macierz = np.zeros((len(termy_stem), len(unikaty)), int)\n",
    "    \n",
    "    for doc in range(len(termy_stem)):\n",
    "        for term in termy_stem[doc]:\n",
    "            for i, unikat in enumerate(unikaty):\n",
    "                if unikat == term: \n",
    "                    macierz[doc,i] += 1\n",
    "                    \n",
    "    return macierz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macierz = np.zeros((len(termy_stem), len(unikaty)), int)\n",
    "macierz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tworz_dtm(termy_stem, unikaty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtm[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unikaty_np = np.array(unikaty)\n",
    "print(unikaty_np[dtm[1,] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_np = np.array([f'doc{i}' for i in range(1, len(tekst)+1)])\n",
    "print(doc_id_np[dtm[:,0] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macierz term-dokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm = np.transpose(dtm)\n",
    "tdm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tdm[:,1])\n",
    "unikaty_np = np.array(unikaty)\n",
    "print(unikaty_np[tdm[:,1] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  rozkład najliczniejszych termów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma_col=dtm.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(suma_col)\n",
    "print(suma_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = list(zip(unikaty, suma_col))\n",
    "bow.sort(key=lambda el: el[1])\n",
    "# print(bow[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.barh(*zip(*bow[-20:]), align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  liczebność termów w dokumentach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma_row=dtm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(suma_row)\n",
    "print(suma_row.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dok_licz = list(zip(doc_id_np, suma_row))\n",
    "dok_licz.sort(key=lambda el: el[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "dok, licz = zip(*dok_licz)\n",
    "plt.barh(dok,licz, align='center')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
